{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import requests\n",
    "import lxml\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "pd.set_option('display.max_columns', 99)\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Cities to Scrape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this analysis, we are interested in the top 30 cities by population.  To find this information, lets scrape it from a reliable, up-to-date source found at this [Wikipedia link]('https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HEADERS = {'User-Agent':'Mozilla/6.0'}\n",
    "BASE_URL = \"https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\"\n",
    "response = requests.get(BASE_URL,headers=HEADERS)\n",
    "soup = BeautifulSoup(response.content, \"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locate the table containing cities and populations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "table = soup.select_one('table.sortable.wikitable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row in the population table, pull the city name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "city_list = []\n",
    "for row in table.select('tr'):\n",
    "    city = row.find('a').text\n",
    "    city_list.append(city)\n",
    "#Truncate the list to limit to first 50 cities\n",
    "city_list = city_list[1:51]\n",
    "#Correct 'Washington' to 'Washington, D.C.'\n",
    "city_list[20] = \"Washington, D.C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['New York',\n",
       " 'Los Angeles',\n",
       " 'Chicago',\n",
       " 'Houston',\n",
       " 'Phoenix',\n",
       " 'Philadelphia',\n",
       " 'San Antonio',\n",
       " 'San Diego',\n",
       " 'Dallas',\n",
       " 'San Jose',\n",
       " 'Austin',\n",
       " 'Jacksonville',\n",
       " 'San Francisco',\n",
       " 'Columbus',\n",
       " 'Indianapolis',\n",
       " 'Fort Worth',\n",
       " 'Charlotte',\n",
       " 'Seattle',\n",
       " 'Denver',\n",
       " 'El Paso',\n",
       " 'Washington, D.C',\n",
       " 'Boston',\n",
       " 'Detroit',\n",
       " 'Nashville',\n",
       " 'Memphis',\n",
       " 'Portland',\n",
       " 'Oklahoma City',\n",
       " 'Las Vegas',\n",
       " 'Louisville',\n",
       " 'Baltimore',\n",
       " 'Milwaukee',\n",
       " 'Albuquerque',\n",
       " 'Tucson',\n",
       " 'Fresno',\n",
       " 'Sacramento',\n",
       " 'Mesa',\n",
       " 'Kansas City',\n",
       " 'Atlanta',\n",
       " 'Long Beach',\n",
       " 'Colorado Springs',\n",
       " 'Raleigh',\n",
       " 'Miami',\n",
       " 'Virginia Beach',\n",
       " 'Omaha',\n",
       " 'Oakland',\n",
       " 'Minneapolis',\n",
       " 'Tulsa',\n",
       " 'Arlington',\n",
       " 'New Orleans',\n",
       " 'Wichita']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pull Yelp.com's business links and store in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(city_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_links = []\n",
    "\n",
    "for i, city in enumerate(city_list):\n",
    "    BASE_URL = 'http://www.yelp.com/search?find_desc=Bars&find_loc=' + city + '&start='\n",
    "    page_counts = [0,10,20,30]\n",
    "    for page_limit in page_counts:\n",
    "        response = requests.get(BASE_URL +  str(page_limit) + '&sortby=review_count',headers=HEADERS)\n",
    "        soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "        links = soup.findAll(\"a\", { \"class\" : \"biz-name js-analytics-click\" })\n",
    "        for link in links:\n",
    "            page_links.append(link['href'])\n",
    "        time.sleep(5)\n",
    "    print(city)\n",
    "#     if i % 5 == 0:\n",
    "#         print(float(i/len(city_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dir = \"/Users/Collier/Dropbox/Skills/Python/Projects/Culture/Cities_Bars_Yelp/\"\n",
    "os.chdir(dir)\n",
    "page_links_save = pd.DataFrame(page_links)\n",
    "page_links_save.to_csv(dir+'business_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in from pc\n",
    "dir = \"C:\\\\Users\\\\David\\\\Dropbox\\\\Skills\\\\Python\\\\Projects\\\\Culture\\\\Cities_Bars_Yelp\\\\\"\n",
    "page_links = pd.read_csv(dir+\"business_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2004"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop Through Yelp Links and Scrape Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've pulled links for about 1200 bars across 30 cities.  Now, we will scrape each Yelp page and pull the details for each business."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BASE_URL = 'http://www.yelp.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['Name','Rating','Reviews','Area','Address',\n",
    "'Takes Reservations','Parking','Bike Parking',\n",
    "'Good for Groups','Ambience','Noise Level',\n",
    "'Music','Good For Dancing','Alcohol','Happy Hour',\n",
    "'Best Nights','Smoking','Outdoor Seating','Wi-Fi',\n",
    "'Has TV','Waiter Service','Has Pool Table','Price_Range','Price_Level']\n",
    "df_master = pd.DataFrame(columns=cols)\n",
    "df_master.reset_index(drop=True,inplace=True)\n",
    "df_master_all = df_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Area</th>\n",
       "      <th>Address</th>\n",
       "      <th>Takes Reservations</th>\n",
       "      <th>Parking</th>\n",
       "      <th>Bike Parking</th>\n",
       "      <th>Good for Groups</th>\n",
       "      <th>Ambience</th>\n",
       "      <th>Noise Level</th>\n",
       "      <th>Music</th>\n",
       "      <th>Good For Dancing</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Happy Hour</th>\n",
       "      <th>Best Nights</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>Outdoor Seating</th>\n",
       "      <th>Wi-Fi</th>\n",
       "      <th>Has TV</th>\n",
       "      <th>Waiter Service</th>\n",
       "      <th>Has Pool Table</th>\n",
       "      <th>Price_Range</th>\n",
       "      <th>Price_Level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Rating, Reviews, Area, Address, Takes Reservations, Parking, Bike Parking, Good for Groups, Ambience, Noise Level, Music, Good For Dancing, Alcohol, Happy Hour, Best Nights, Smoking, Outdoor Seating, Wi-Fi, Has TV, Waiter Service, Has Pool Table, Price_Range, Price_Level]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master_all.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>/biz/lemongrass-taste-of-vietnam-wichita?osq=Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>/biz/bubbas-33-wichita?osq=Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001</th>\n",
       "      <td>/biz/logans-roadhouse-wichita-2?osq=Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002</th>\n",
       "      <td>/biz/heroes-sports-bar-and-grill-wichita-2?osq=Bars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>/biz/rain-caf%C3%A9-and-lounge-wichita-2?osq=Bars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "1999  /biz/lemongrass-taste-of-vietnam-wichita?osq=Bars  \n",
       "2000  /biz/bubbas-33-wichita?osq=Bars                    \n",
       "2001  /biz/logans-roadhouse-wichita-2?osq=Bars           \n",
       "2002  /biz/heroes-sports-bar-and-grill-wichita-2?osq=Bars\n",
       "2003  /biz/rain-caf%C3%A9-and-lounge-wichita-2?osq=Bars  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_links.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "page_links2 = page_links['0'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0499001996007984\n",
      "0.0998003992015968\n",
      "0.1497005988023952\n",
      "0.1996007984031936\n",
      "0.249500998003992\n",
      "0.2994011976047904\n",
      "0.34930139720558884\n",
      "0.3992015968063872\n",
      "0.4491017964071856\n",
      "0.499001996007984\n",
      "0.5489021956087824\n",
      "0.5988023952095808\n"
     ]
    }
   ],
   "source": [
    "# for idx, link in enumerate(page_links):\n",
    "for idx, link in enumerate(page_links2):\n",
    "    response = requests.get(BASE_URL + link, headers=HEADERS)\n",
    "    soup = BeautifulSoup(response.content, \"html5lib\")\n",
    "    #try to find name of establishment\n",
    "    try:\n",
    "        name = soup.find(\"h1\", {\"class\":\"biz-page-title embossed-text-white\"}).contents[0].strip()\n",
    "    except:\n",
    "        #if cannot find name, look at other name location, if cannot find that skip row\n",
    "        try:\n",
    "            name = soup.find(\"h1\", {\"class\":\"biz-page-title embossed-text-white shortenough\"}).contents[0].strip()\n",
    "        except:\n",
    "            continue\n",
    "    feature_attr = soup.select_one('div.short-def-list').select('dt.attribute-key')\n",
    "    feature_response = soup.select_one('div.short-def-list').select('dd')\n",
    "    response = []\n",
    "    #if we successfully scraped the features, loop through and pull text\n",
    "    if feature_response:\n",
    "        for tag in feature_response:\n",
    "            text = tag.text.strip()\n",
    "            response.append(text)\n",
    "    #if the features are missing, skip row\n",
    "    else:\n",
    "        continue\n",
    "    attr = []\n",
    "    #if we successfully scraped the features, loop through and pull text\n",
    "    if feature_attr:\n",
    "        for tag in feature_attr:\n",
    "            text = tag.text.strip()\n",
    "            attr.append(text)\n",
    "    #if the features are missing, skip row\n",
    "    else:\n",
    "        continue\n",
    "    df_bus_info = pd.DataFrame({'VenueAttr_Desc':attr,'VenueAttr_Status':response})\n",
    "    df_bus_info = pd.DataFrame(response,attr)\n",
    "    df_bus_info = df_bus_info.T\n",
    "    try:\n",
    "        pricing = soup.find(\"dd\", { \"class\" : \"nowrap price-description\" }).contents[0].strip()\n",
    "        pricing = pricing.replace(\"$\",\"\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        pricing_level = soup.find(\"span\", {\"class\":\"business-attribute price-range\"}).contents[0].strip()\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        ratings = soup.find('span', {\"class\" : \"review-count rating-qualifier\" }).contents[0].strip()\n",
    "        ratings = ratings.replace(\" reviews\",\"\")\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        stars = str(soup.find('div', {'class': 'biz-rating biz-rating-very-large clearfix'}).contents[1])\n",
    "        stars = stars[stars.find(\"title=\"):]\n",
    "        stars = stars[:stars.find(\"rating\")]\n",
    "        stars = stars[stars.find(\"=\"):]\n",
    "        stars = stars[:stars.find(\" star\")]\n",
    "        stars = re.sub('[^a-zA-Z0-9 \\n\\.]', '', stars)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        address = str(soup.find('strong',{'class':'street-address'}).contents[1])\n",
    "        address = address[:address.find(\"\\n    </address>\")]\n",
    "        address = re.sub(\"<address>\\n        \",\"\",address)\n",
    "        address = re.sub(\"<br/>\",\" \",address)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        area = soup.find('span',{'class':'neighborhood-str-list'}).contents[0]\n",
    "        area = re.sub(\"\\n            \",\"\",area)\n",
    "        area = re.sub(\"        \",\"\",area)\n",
    "    except:\n",
    "        pass\n",
    "    cols = ['Name','Rating','Reviews','Area','Address',\n",
    "    'Takes Reservations','Parking','Bike Parking',\n",
    "    'Good for Groups','Ambience','Noise Level',\n",
    "    'Music','Good For Dancing','Alcohol','Happy Hour',\n",
    "    'Best Nights','Smoking','Outdoor Seating','Wi-Fi',\n",
    "    'Has TV','Waiter Service','Has Pool Table','Price_Range','Price_Level']\n",
    "    df_master = pd.DataFrame(columns=cols,index=[0])\n",
    "    df_master.reset_index(inplace=True)\n",
    "    try:\n",
    "        df_master.loc[0, 'Name'] = name\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Rating'] = stars\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Reviews'] = ratings\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Area'] = area\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Address'] = address\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Takes Reservations'] = df_bus_info.loc[0,'Takes Reservations']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Parking'] = df_bus_info.loc[0,'Parking']\n",
    "    except:\n",
    "        pass\n",
    "    try:    \n",
    "        df_master.loc[0, 'Bike Parking'] = df_bus_info.loc[0,'Bike Parking']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Good for Groups'] = df_bus_info.loc[0,'Good for Groups']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Ambience'] = df_bus_info.loc[0,'Ambience']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Noise Level'] = df_bus_info.loc[0,'Noise Level']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Music'] = df_bus_info.loc[0,'Music']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Good For Dancing'] = df_bus_info.loc[0,'Good For Dancing']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Alcohol'] = df_bus_info.loc[0,'Alcohol']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Happy Hour'] = df_bus_info.loc[0,'Happy Hour']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Best Nights'] = df_bus_info.loc[0,'Best Nights']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Smoking'] = df_bus_info.loc[0,'Smoking']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Outdoor Seating'] = df_bus_info.loc[0,'Outdoor Seating']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Wi-Fi'] = df_bus_info.loc[0,'Wi-Fi']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Has TV'] = df_bus_info.loc[0,'Has TV']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Waiter_Service'] = df_bus_info.loc[0,'Waiter Service']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Has Pool Table'] = df_bus_info.loc[0,'Has Pool Table']\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Price_Range'] = pricing\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        df_master.loc[0, 'Price_Level'] = pricing_level\n",
    "    except:\n",
    "        pass\n",
    "    df_master_all = df_master_all.append(df_master)\n",
    "    time.sleep(10)\n",
    "    if idx % 100 == 0:\n",
    "        print(float(idx/len(page_links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We've successfully pulled destails for 1055 of the 1216 business links.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1466, 26)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_master_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dir = \"/Users/Collier/Dropbox/Skills/Python/Projects/Culture/Cities_Bars_Yelp/\"\n",
    "dir = \"C:\\\\Users\\\\David\\\\Dropbox\\\\Skills\\\\Python\\\\Projects\\\\Culture\\\\Cities_Bars_Yelp\\\\\"\n",
    "os.chdir(dir)\n",
    "# page_links_save = pd.DataFrame(page_links)\n",
    "df_master_all.to_csv(dir+'yelp_data_bars_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "98px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
